classdef LinearRegressionModel < matlab.mixin.SetGet
    %LINEARREGRESSIONMODEL 
    % Class representing an implementation of linear regression model
    
    properties (Access = public)
        optimizer
        trainingData
        theta
        thetaOptimum
    end
    
    methods (Access = public)
        function obj = LinearRegressionModel(varargin)
        % Function Name: LinearRegressionModel
        %
        % Description: Construct an instance of this class
        %
        % Syntax:  obj =
        % LinearRegressionModel('Data','TempearatureMeasurement.mat','Optimizer');
        %
        % Inputs:
        %    Data - LinearRegressionDataFormatter object
        %    Optimizer - GradientDescentOptimizer object
        %
        %
        % Outputs:
        %    obj - callable object
        %
        % $Revision: R2022a$
        % $Author: Christian Lange$
        % $Date: April 12, 2022$
            
            % ========= YOUR CODE HERE =========
            % perform the varargin
            for i = 1:nargin
                if strcmp(varargin{i},'Data')
                    obj.trainingData = varargin{i+1};
                elseif strcmp(varargin{i},'Optimizer')
                    obj.optimizer = varargin{i+1};
                end
            end

            obj.initializeTheta();
        end
        
        function J = costFunction(obj)
        % Function Name: costFunction
        %
        % Description: calculates the costs by using specific thetas 
        %
        % Syntax:  J = GradientDescentOptimizer(obj)
        %
        % Inputs:
        %    obj - LinearRegressionModel object 
        %
        %
        % Outputs:
        %    J - costs
        %
        % $Revision: R2022a$
        % $Author: Christian Lange$
        % $Date: April 12, 2022$     

            m = obj.trainingData.numOfSamples; 
            
            % ========= YOUR CODE HERE =========
            % compute the costs
            % therefore use the hypothesis function as well
            % this calculation can be done by one line of code
            % returns the cost value J 
            J = 1/(2*m) * sum((obj.hypothesis()-obj.trainingData.commandVar).^2);
        end
        
        function hValue = hypothesis(obj)
            % ========= YOUR CODE HERE =========
            % compute the hypothesis values for each sample
            % therefore compute the matrix multiplication with X
            % this calculation can be done by one line of code
            hValue = obj.theta(1) + obj.theta(2)*obj.trainingData.feature;
        end
        
        function h = showOptimumInContour(obj)
            h = figure('Name','Optimum');
            theta0_vals = linspace(50, 150, 100);
            theta1_vals = linspace(0, 2, 100);
            
            % ========= YOUR CODE HERE =========
            % compute the costs for each theta_vals tuple
            % plot the costs with the contour command
            % add x and y label
            % add the optimum theta value to the plot (red X, MarkerSize: 10, LineWidth: 2)
            costs = zeros(obj.trainingData.numOfSamples);
            for i = 1:length(theta1_vals)
                for k = 1:length(theta0_vals)
                    obj.setTheta(theta0_vals(k), theta1_vals(i))
                    costs(i, k) = obj.costFunction();
                end
            end
            contour(theta0_vals, theta1_vals, costs);
            hold on;
            plot(obj.thetaOptimum(1), obj.thetaOptimum(2), 'rx', 'LineWidth',2, 'MarkerSize',10);
            xlabel("theta0");
            ylabel("theta1");
        end
        
        function h = showCostFunctionArea(obj)
        % Function Name: showCostFunctionArea
        %
        % Description: calculates the costs by using specific thetas 
        %
        % Syntax:  J = GradientDescentOptimizer(obj)
        %
        % Inputs:
        %    obj - LinearRegressionModel object 
        %
        %
        % Outputs:
        %    J - costs
        %
        % $Revision: R2022a$
        % $Author: Christian Lange$
        % $Date: April 12, 2022$     
            h = figure('Name','Cost Function Area');
            theta0_vals = linspace(50, 150, 100);
            theta1_vals = linspace(0, 2, 100);
            
            % ========= YOUR CODE HERE =========
            % compute the costs for each theta_vals tuple
            % plot the costs with the surf command
            % add x and y label
            costs = zeros(obj.trainingData.numOfSamples);
            for i = 1:length(theta1_vals)
                for k = 1:length(theta0_vals)
                    obj.setTheta(theta0_vals(k), theta1_vals(i))
                    costs(i, k) = obj.costFunction();
                end
            end
            surf(theta0_vals,theta1_vals,costs);
            xlabel("theta1");
            ylabel("theta0");
            zlabel("costs");
        end
        
        function h = showTrainingData(obj)
           h = figure('Name','Linear Regression Model');
           plot(obj.trainingData.feature,obj.trainingData.commandVar,'rx')
           grid on;
           xlabel(obj.trainingData.featureName + " in Kelvin");
           ylabel(obj.trainingData.commandVarName + " in Kelvin");
           legend('Training Data')
        end
        
        function h = showModel(obj)
           h = obj.showTrainingData();
           
           % ========= YOUR CODE HERE =========
           % add the final trained model plot to the figure ('b-')
           % update the legend
           hold on
           plot(obj.trainingData.feature, obj.hypothesis(),'b-');
           legend('Training Data', 'Linear Regression Model')
        end
        
        function setTheta(obj,theta0,theta1)
            obj.theta = [theta0;theta1];
        end
        
        function setThetaOptimum(obj,theta0,theta1)
            obj.thetaOptimum = [theta0;theta1];
        end
    end
    
    methods (Access = private)
        
        function initializeTheta(obj)
            obj.setTheta(0,0);
        end
   
    end
end


